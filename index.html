
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      <link rel="icon" href="assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.1.2, mkdocs-material-7.1.5">
    
    
      
        <title>Web Mining A 2021</title>
      
    
    
      <link rel="stylesheet" href="assets/stylesheets/main.bde7dde4.min.css">
      
        
        <link rel="stylesheet" href="assets/stylesheets/palette.ef6f36e2.min.css">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>:root{--md-text-font-family:"Roboto";--md-code-font-family:"Roboto Mono"}</style>
      
    
    
    
    
      
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="none" data-md-color-accent="none">
  
    
    <script>function __prefix(e){return new URL(".",location).pathname+"."+e}function __get(e,t=localStorage){return JSON.parse(t.getItem(__prefix(e)))}</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#web-mining-a-2021" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="." title="Web Mining A 2021" class="md-header__button md-logo" aria-label="Web Mining A 2021" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Web Mining A 2021
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Web Mining A 2021
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="." title="Web Mining A 2021" class="md-nav__button md-logo" aria-label="Web Mining A 2021" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    Web Mining A 2021
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Web Mining A 2021
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="." class="md-nav__link md-nav__link--active">
        Web Mining A 2021
      </a>
      
        
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#pengantar" class="md-nav__link">
    Pengantar
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#web-crawling" class="md-nav__link">
    Web Crawling
  </a>
  
    <nav class="md-nav" aria-label="Web Crawling">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pengertian" class="md-nav__link">
    Pengertian
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#uji-coba-web-crawling" class="md-nav__link">
    Uji Coba Web Crawling
  </a>
  
    <nav class="md-nav" aria-label="Uji Coba Web Crawling">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#penjelasan-code" class="md-nav__link">
    Penjelasan Code
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#text-preprocessing" class="md-nav__link">
    Text Preprocessing
  </a>
  
    <nav class="md-nav" aria-label="Text Preprocessing">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#case-folding" class="md-nav__link">
    Case Folding
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tokenization-dan-filtering" class="md-nav__link">
    Tokenization dan Filtering
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#steeming" class="md-nav__link">
    Steeming
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#reduksi-dimensi" class="md-nav__link">
    Reduksi Dimensi
  </a>
  
    <nav class="md-nav" aria-label="Reduksi Dimensi">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#implementasi-text-preprocessing" class="md-nav__link">
    Implementasi Text Preprocessing
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modelling" class="md-nav__link">
    Modelling
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#pengantar" class="md-nav__link">
    Pengantar
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#web-crawling" class="md-nav__link">
    Web Crawling
  </a>
  
    <nav class="md-nav" aria-label="Web Crawling">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pengertian" class="md-nav__link">
    Pengertian
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#uji-coba-web-crawling" class="md-nav__link">
    Uji Coba Web Crawling
  </a>
  
    <nav class="md-nav" aria-label="Uji Coba Web Crawling">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#penjelasan-code" class="md-nav__link">
    Penjelasan Code
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#text-preprocessing" class="md-nav__link">
    Text Preprocessing
  </a>
  
    <nav class="md-nav" aria-label="Text Preprocessing">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#case-folding" class="md-nav__link">
    Case Folding
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tokenization-dan-filtering" class="md-nav__link">
    Tokenization dan Filtering
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#steeming" class="md-nav__link">
    Steeming
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#reduksi-dimensi" class="md-nav__link">
    Reduksi Dimensi
  </a>
  
    <nav class="md-nav" aria-label="Reduksi Dimensi">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#implementasi-text-preprocessing" class="md-nav__link">
    Implementasi Text Preprocessing
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modelling" class="md-nav__link">
    Modelling
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
                
                <h1 id="web-mining-a-2021">Web Mining A 2021</h1>
<p>Teknik Informatika Universitas Trunojoyo Madura</p>
<p><strong>Nama: Ahmad Wahyudi</strong></p>
<p><strong>NIM: 160411100093</strong></p>
<p><strong>Dosen Pengampu: Mula'ab, S.Si., M.Kom.</strong></p>
<h2 id="pengantar"><strong>Pengantar</strong></h2>
<blockquote>
<p>Di zaman sekarang teknologi Internet telah berkembang dengan sangat pesat. Singkatnya kebutuhan akan informasi dan data sekarang tidak lepas dari mengakses Internet dan membuka website untuk menunjang pekerjaan sehari-hari seperti membaca berita, menulis, menonton hiburan, dan sebagainya. Namun karena Informasi dan data yang tersebar sangatlah banyak serta keterbatasan manusia dalam mengumpulkan informasi dan data yang dibutuhkan, maka manusia mulai memanfaatkan teknologi untuk memudahkan kita dalam melakukan pengumpulan informasi dan data. salah satunya adalah dengan melakukan <strong>Web Crawling</strong>.</p>
</blockquote>
<h2 id="web-crawling"><strong>Web Crawling</strong></h2>
<h3 id="pengertian"><strong>Pengertian</strong></h3>
<blockquote>
<p><strong>Web Crawling</strong> atau biasa disebut dengan spiders adalah proses di mana mesin pencari mengirimkan tim robot (crawler atau spider) untuk menemukan konten baru dan konten yang telah di-update. Konten yang dimaksud bisa beragam, mulai dari sebuah dokumen, gambar, video, audio, dan lain sebagainya.</p>
<p>Untuk melakukan web crawling, kita setidaknya harus memiliki pengetahuan dasar tentang <strong>HTML</strong> karena semua website yang akan kita crawling menggunakan teknologi tersebut. </p>
<p>Pada kesempatan kali ini, kita akan menggunakan bahasa pemrograman <strong>Python</strong> serta library <strong>Scrapy</strong> untuk melakukan proses crawling data. Website yang akan kita gunakan dalam ujicoba kali ini adalah <a href="https://www.muslim.or.id">Muslim.or.id</a>.</p>
</blockquote>
<h3 id="uji-coba-web-crawling"><strong>Uji Coba Web Crawling</strong></h3>
<blockquote>
<p>Seperti yang telah disebutkan diatas bahwa website yang akan kita jadikan objek ujicoba adalah <a href="https://www.muslim.or.id">Muslim.or.id</a> yang merupakan salah satu media Islam yang banyak membahas mengenai seputar hukum-hukum islam yang banyak mengandung manfaat bagi kaum muslimin. Artikel didalam website tersebut terdiri dari berbagai macam disiplin ilmu. </p>
<p>Pertama, kita tentukan terlebih dahulu halaman yang akan kita ekstrak datanya. </p>
</blockquote>
<p><a href="https://muslim.or.id/category/aqidah">https://muslim.or.id/category/aqidah</a></p>
<p>Buka command prompt kemudian ketik:</p>
<pre><code>C:\Users\AHMAD WAHYUDI\Desktop&gt;scrapy startproject muslim_project
</code></pre>
<p>Kemudian masuk kedalam direktori project:</p>
<pre><code>C:\Users\AHMAD WAHYUDI\Desktop&gt;cd muslim_project
</code></pre>
<p>Masukkan link <a href="https://muslim.or.id/category/aqidah">https://muslim.or.id/category/aqidah</a></p>
<pre><code>C:\Users\AHMAD WAHYUDI\Desktop\muslim_project&gt;scrapy genspider muslim https://muslim.or.id/category/aqidah
</code></pre>
<p>Buka folder <code>muslim_project</code>. Didalamnya akan terdapat folder <code>spiders</code> yang di <em>generate</em> dari hasil menjalankan perintah diatas. Didalam folder <code>spiders</code> akan ada file yang bernama <code>almanhaj</code>. Buka file tersebut dengan text-editor. Dalam hal ini saya menggunakan <code>Vs-Code</code>.</p>
<pre><code class="language-python">import scrapy

class MuslimSpider(scrapy.Spider):
    name = 'muslim'
    allowed_domains = ['https://muslim.or.id/category/aqidah']
    start_urls = ['http://https://muslim.or.id/category/aqidah/']

    def parse(self, response):
        pass
</code></pre>
<p>Edit source code pada bagian </p>
<pre><code class="language-python">def parse(self, response):
        pass 
</code></pre>
<p>sehingga menjadi seperti</p>
<pre><code class="language-python"> def parse(self, response):
        data = response.css('.post-box')
        for item in data:
            title = item.css('.post-title a::text ').extract()
            author = item.css('.post-meta-author a::text').extract()
            yield{
                'Judul Artikel': title ,
                'Penulis': author
            }
</code></pre>
<h4 id="penjelasan-code">Penjelasan Code</h4>
<p><code>data = response.css('.post-box')</code> - nama class dimana data yang akan diestrak berada.  </p>
<p>Karena kita akan mengambil nama judul dan nama penulis, kita perlu mengetahui nama class yang menampung judul dan penulis, maka </p>
<pre><code class="language-python">for item in data:
    title = item.css('.post-title a::text ').extract()
    author = item.css('.post-meta-author a::text').extract()
    yield{
        'Judul Artikel': title ,
        'Penulis': author
        }
</code></pre>
<p>Untuk melakukan ekstraksi data, buka terminal atau command prompt kemudian ketikkan perintah</p>
<pre><code>C:\Users\AHMAD WAHYUDI\Desktop\muslim_project&gt; scrapy crawl muslim -o hasil.csv
</code></pre>
<p>Data yang kita crawl akan tersimpan dengan nama <code>hasil.csv</code>. Berikut isi dari file <code>hasil.csv</code></p>
<pre><code>judul,penulis
&quot;Makna, Rukun dan Syarat Kalimat Tauhid&quot;,Dimas Setiaji
Makna Syirik dan Larangan Berbuat Syirik,&quot;Yulian Purnama, S.Kom.&quot;
Nasib Ahli Tauhid di Akhirat (Bag. 2),Sa'id Abu Ukkasyah
Nasib Ahli Tauhid di Akhirat (Bag. 1),Sa'id Abu Ukkasyah
Tanda Pengagungan kepada Allah,&quot;Ari Wahyudi, S.Si.&quot;
Pengaruh Nama dan Sifat Allah bagi Insan Beriman (Bag. 2),&quot;dr. Adika Mianoki, Sp.S.&quot;
Pengaruh Nama dan Sifat Allah bagi Insan Beriman (Bag. 1),&quot;dr. Adika Mianoki, Sp.S.&quot;
Ngaji Aqidah Sampai Kapan?,&quot;Ari Wahyudi, S.Si.&quot;
Agama Para Rasul Itu Satu,&quot;dr. M Saifudin Hakim, M.Sc., Ph.D.&quot;
Adakah Nabi dari Kalangan Wanita?,&quot;dr. M Saifudin Hakim, M.Sc., Ph.D.&quot;
Adakah Rasul dari Kalangan Jin?,&quot;dr. M Saifudin Hakim, M.Sc., Ph.D.&quot;
Tidak Ada Dukun Putih,&quot;Yulian Purnama, S.Kom.&quot;
Larangan Sangat Keras Pergi ke Dukun,&quot;dr. Adika Mianoki, Sp.S.&quot;
</code></pre>
<h2 id="text-preprocessing"><strong>Text Preprocessing</strong></h2>
<p>Setelah melakukan pengumpulan data maka kita akan lanjut ke tahap berikutnya yaitu <strong>Text Preprocessing</strong>.</p>
<p><strong>Text Preprocessing</strong> merupakan tahapan dimana data yang sudah kita dapatkan dari hasil crawling tadi diseleksi terlebih dahulu agar nantinya data yang kita olah lebih terstruktur.</p>
<p>Sebenarnya tidak ada aturan tahapan yang pasti didalam proses Text Preprocessing karena semuanya bergantung pada jenis data dan hasil yang kita inginkan.
 Tetapi secara umum tahapan pada Text Preprocessing adalah <em>Case Folding, Tokenization dan Filtering, Stopword Removal, Stemming</em>. </p>
<h3 id="case-folding">Case Folding</h3>
<p>Proses case folding bertujuan untuk mengubah semua huruf dalam sebuah dokumen teks menjadi huruf kecil (lowercase). Untuk proses ini kita bisa menggunakan fungsi lower() yang merupakaan bawaan dari python dan library pandas.</p>
<p>Pertama kita mulai dengan membaca file <code>hasil.csv</code> </p>
<pre><code class="language-python">import pandas as pd
data = pd.read_csv(&quot;hasil.csv&quot;)
data.head()
</code></pre>
<p>Outputnya:</p>
<p><img alt="hasil.csv" src="casefold1.png" /></p>
<p>Langkah selanjutnya, kita akan mengubah seluruh huruf didalam file <code>hasil.csv</code> menjadi lowercase seluruhnya dengan menggunakan perintah <strong>lower()</strong></p>
<pre><code class="language-python">def casefold(text):
    return str.lower(text)

print('Hasil Case Folding: \n')
for item in data:
    items = data[item] = (data[item].apply(casefold))
    print(items.head())
</code></pre>
<p>Outputnya:</p>
<p><img alt="lowercase" src="casefold2.png" /></p>
<h3 id="tokenization-dan-filtering">Tokenization dan Filtering</h3>
<p>Pada tahapan <strong>tokenization dan filtering</strong> kita akan melakukan proses:</p>
<ul>
<li>menghilangkan angka pada teks</li>
<li>menghilangkan tanda baca </li>
<li><code>word_tokenize</code> - untuk memecah string kedalam tokens</li>
</ul>
<p><strong>Menghilangkan angka pada teks</strong></p>
<p>Dengan memanfaatkan fungsi <strong>str.replace</strong>  yang merupakan bawaan dari Python kita akan menghapus angka pada teks</p>
<pre><code class="language-python">def remove_number(text):
    return  re.sub(r&quot;\d+&quot;, &quot;&quot;, text)
print ('Hapus Angka: \n')
for item in data:
    items=data[item]=data[item].apply(remove_number)
    print(items.head())
</code></pre>
<p>Outputnya:</p>
<p><img alt="hapusangka" src="casefold3.png" /></p>
<p><strong>Menghilangkan tanda baca pada teks</strong></p>
<p>Source code untuk menghapus tanda baca pada teks dengan kombinasi fungsi string <strong>.translate</strong> - <strong>.maketrans</strong> - <strong>string.punctuation</strong> </p>
<pre><code class="language-python">def remove_punctuation(text):
    return text.translate(str.maketrans(&quot;&quot;,&quot;&quot;,string.punctuation))

print ('Menghilangkan tanda baca: \n')
for item in data:
    items = data[item] = data[item].apply(remove_punctuation)
    print(items.head())
</code></pre>
<p>Outputnya:</p>
<p><img alt="hapustandabaca" src="casefold4.png" /></p>
<p><strong>Word Tokenization</strong></p>
<p>Disini kita akan menggunakan libary nltk untuk memecah string kedalam tokens</p>
<pre><code class="language-python">def word_tokenize_wrapper(text):
    return word_tokenize(text)
for item in data:
    item_tokens = data[item] = data[item].apply(word_tokenize_wrapper)
    print(item_tokens.head())
</code></pre>
<p>Outputnya:</p>
<p><img alt="tokenization" src="tokenization1.png" /></p>
<p><strong>Frekuensi Token</strong></p>
<p>Untuk mendapatkan frekuensi dari proses tokenization kita menggunakan fungsi <strong>FreqDist</strong> dan <strong>.most_common()</strong> yang tersedia di nltk</p>
<pre><code class="language-python">def freqDist_wrapper(text):
    return FreqDist(text)
print ('Frequency Tokens: \n')
for item in data:
    item_tokens_fdist = data[item] = data[item].apply(freqDist_wrapper)
    print(item_tokens_fdist.head().apply(lambda x:x.most_common()))
</code></pre>
<p>Outputnya:</p>
<p><img alt="freqDist" src="tokenization2.png" /></p>
<p><strong>Filtering</strong></p>
<p>Pada Tahap ini dengan menggunakan stopword bahasa Indonesia dari library NLTK, kita akan melakukan filtering terhadap dataframe yang sudah mengalami proses tokenization</p>
<pre><code class="language-python">list_stopwords = stopwords.words('indonesian')
list_stopwords = set(list_stopwords)
def stopwords_removal(words):
    return [word for word in words if word not in list_stopwords]
for item in data:
    item_tokens_WSW = item_tokens_fdist = data[item].apply(stopwords_removal)
    print (item_tokens_WSW.head())
</code></pre>
<p>Outputnya:</p>
<p><img alt="filtering" src="filtering1.png" /></p>
<h3 id="steeming">Steeming</h3>
<p>Steeming merupakan tahapan dimana kata yang sudah kita dapatkan ditransformasikan menjadi kata dasarnya. Contoh <strong>membantu</strong> ditransformasikan menjadi <strong>bantu</strong> dan seterusnya. Dalam tahapan ini kita akan menggunakan library python Sastrawi untuk melakukan proses Steeming.</p>
<pre><code class="language-python">def stemm_wrapper(text):
    factory = StemmerFactory()
    stemmer = factory.create_stemmer()
    return stemmer.stem(text)
text = 'Steeming merupakan tahapan dimana kata yang sudah kita dapatkan ditransformasikan menjadi kata dasarnya. Contoh membantu ditransformasikan menjadi bantu dan seterusnya. Dalam tahapan ini kita akan menggunakan library python Sastrawi untuk melakukan proses Steeming.'
result = stemm_wrapper(text)
print (result)
</code></pre>
<p>Outputnya:</p>
<pre><code>```
steeming rupa tahap mana kata yang sudah kita dapat transformasi jadi kata dasar contoh bantu transformasi jadi bantu dan terus dalam tahap ini kita akan guna library python sastrawi untuk laku proses steeming
```
</code></pre>
<h2 id="reduksi-dimensi">Reduksi Dimensi</h2>
<p>Reduksi Dimensi adalah teknik untuk mengurangi dimensi dataset dalam hal ini fitur data. Dataset yang berjumlah puluhan bahkan ratusan fitur atau kolom dapat kita kurangi jumlah fitur atau kolomnya tanpa menghilangkan informasi dari dataset.</p>
<p>Pada prinsipnya, reduksi dimensi sama dengan mengkompres file yang berukuran besar menjadi zip. Kompresi file tidak akan mengurangi informasi yang ada di dalam file tersebut, hanya membuatnya lebih sederhana sehingga mengurangi ukuran file yang dapat mempercepat proses transfer file.</p>
<h3 id="implementasi-text-preprocessing">Implementasi Text Preprocessing</h3>
<pre><code class="language-python">import numpy as np
import PyPDF2
import doctest
import sys
from IPython.display import Image
from requests_html import HTMLSession
import matplotlib.pyplot as plt
%matplotlib inline 
import networkx as nx
from nltk.tokenize.punkt import PunktSentenceTokenizer
from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer
</code></pre>
<pre><code class="language-python">session = HTMLSession()
r = session.get('https://muslim.or.id/65984-makna-syirik-dan-larangan-berbuat-syirik.html')
articles = r.html.find('div.post-65984')

for item in articles:
    docsitem = item.find('div.entry', first = True)
    docs = docsitem.text
    print(docs)
</code></pre>
<pre><code class="language-python">doc_tokenizer = PunktSentenceTokenizer()
sentences_list = doc_tokenizer.tokenize(news)
type(sentences_list)
</code></pre>
<pre><code class="language-python">import string
from Sastrawi.Stemmer.StemmerFactory import StemmerFactory
factory = StemmerFactory()
stemmer = factory.create_stemmer()
import re
docsre = []
for item in sentences_list:
    result = re.sub(r&quot;\d+&quot;,&quot;&quot;,item)
    docsre.append(result)
print (docsre)
</code></pre>
<pre><code class="language-python">len(docsre)
docs = []
for item in docsre:
    result = item.replace ('\n','')
    docs.append(result)
print(docs)
</code></pre>
<pre><code class="language-python">from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory
from nltk.tokenize import word_tokenize
factory = StopWordRemoverFactory()
stopword  = factory.create_stop_word_remover()

len_docs= len(docs)
docsstop = []
for item in range (0, len_docs):
    sentence = stopword.remove(docs[item])
    docsstop.append(sentence)
print(docsstop)
</code></pre>
<pre><code class="language-python">cv = CountVectorizer()
cv_matrix = cv.fit_transform(docs)
a = cv_matrix.toarray()
a.shape
</code></pre>
<pre><code class="language-python">factory = StemmerFactory()
stemmer = factory.create_stemmer()
docsstemm = []
for item in docsstop:
    output_stemm = stemmer.stem(item)
    docsstemm.append(output_stemm)
print(docsstemm)
</code></pre>
<pre><code class="language-python">bag = cv.fit_transform(docsstemm)
print(cv.vocabulary_)
</code></pre>
<pre><code class="language-python">print(cv.get_feature_names())
len(cv.get_feature_names())
bag = cv.fit_transform(docsstemm)
matrik_vsm = bag.toarray()
matrik_vsm.shape
matrik_vsm[0]
</code></pre>
<pre><code class="language-python">import pandas as pd
a = cv.get_feature_names()
print(len(matrik_vsm[:,1]))
print(len(matrik_vsm[:,1]))
dfb = pd.DataFrame(data=matrik_vsm, index= list(range(1, len(matrik_vsm[:,1])+1,)), columns=[a])
dfb
</code></pre>
<pre><code class="language-python">from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.preprocessing import normalize
# normed_x = normalize(x, axis=0, norm='l2')
tfidf  = TfidfTransformer(use_idf=True,norm='l2',smooth_idf=True)
tf= tfidf.fit_transform(cv.fit_transform(docsstemm)).toarray()
dfb = pd.DataFrame(data=tf, index=list(range(1, len(tf[:,1])+1,)),columns=[a])
dfb
</code></pre>
<h2 id="modelling">Modelling</h2>
<p>Dalam Text Modelling kali ini kita akan meringkas dokumen menggunakan metode LSA (Latent Semantic Analysis) juga dikenal sebagai LSI (Latent Semantic Index) LSA menggunakan bag of word(BoW) model, yang menghasilkan term-document matrix (kemunculan term dalam sebuah dokumen). Baris mewakili istilah dan kolom mewakili dokumen.  LSA biasanya digunakan sebagai teknik pengurangan dimensi atau pengurangan kebisingan.</p>
<p>Dokumen yang kita gunakan adalah artikel dari <a href="https://muslim.or.id/65984-makna-syirik-dan-larangan-berbuat-syirik.html">muslim.or.id</a></p>
<p>Implementasi Text Modelling:</p>
<pre><code class="language-python">import codecs
import string 
import operator
import numpy as np
from nltk.tokenize import sent_tokenize
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.utils.extmath import randomized_svd
from requests_html import HTMLSession
from Sastrawi.Stemmer.StemmerFactory import StemmerFactory# create stemmer
from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory #untuk stopword remove
from nltk.tokenize.punkt import PunktSentenceTokenizer

session = HTMLSession()
r = session.get('https://muslim.or.id/65984-makna-syirik-dan-larangan-berbuat-syirik.html')
articles = r.html.find('div.post-65984')

for item in articles:
    newsitem = item.find('div.entry', first = True)
    news = newsitem.text
    print(news)
sent_tokenize_list = sent_tokenize(news)
stopwords= set(StopWordRemoverFactory().get_stop_words())
#Menghitung TF-IDF
vectorizer = TfidfVectorizer(stop_words=stopwords, use_idf=True, ngram_range = (1, 3))
X = vectorizer.fit_transform(sent_tokenize_list) 
X_T = np.transpose(X)
U, Sigma, VT = randomized_svd(X_T, n_components=100, n_iter=100, random_state=None)
k = 4
temp_k = k
i = 0 
index = 0 
output = []
index_list = []

if temp_k &lt;= 4:
    dic = {}
    for j in range(0, len(VT[0])):
        dic[j] = VT[0][j]
    dic_sort = sorted(dic.items(), key=operator.itemgetter(1))

    index1 = dic_sort[-1][0]
    index2 = dic_sort[-2][0]
    index3 = dic_sort[-3][0]
    index4 = dic_sort[-4][0]
    list = [index1, index2,index3,index4]
    list = sorted(list)
    if k == 1:
        output.append(sent_tokenize_list[list[0]])
    if k == 2:
        output.append(sent_tokenize_list[list[0]])
        output.append(sent_tokenize_list[list[1]])
    if k ==3:
        output.append(sent_tokenize_list[list[0]])
        output.append(sent_tokenize_list[list[1]])
        output.append(sent_tokenize_list[list[2]])
    if k ==4:
        output.append(sent_tokenize_list[list[0]])
        output.append(sent_tokenize_list[list[1]])
        output.append(sent_tokenize_list[list[2]])
        output.append(sent_tokenize_list[list[3]])

summarized_text = &quot; &quot;.join(output)

print(&quot;Hasil rangkuman: \n&quot;,summarized_text)

</code></pre>
<p>Evaluasi 
Evaluasi ringkasan otomatis dapat dilakukan dengan banyak cara. Yang paling sering digunakan adalah ROUGE-n. ROUGE sendiri merupakan seperangkat metrik untuk mengevaluasi ringkasan teks otomatis yang bekerja dengan cara membandingkan suatu ringkasan otomatis atau terjemahan dengan seperangkat rangkuman referensi.</p>
<p>Pengukuran ROUGE terbagi menjadi beberapa:</p>
<ul>
<li>
<p>ROUGE-N yang digunakan untuk mengukur unigram, bigram, trigram, dan n-gram yang lebih tinggi lagi</p>
</li>
<li>
<p>ROUGE-L yang digunakan untuk mengukur pencocokan kata terpanjang menggunakan LCS.</p>
</li>
<li>
<p>ROUGE-S yang juga bisa disebut sebagai skip-gram cooccurence. Misalnya, skip-bigram mengukur overlap dari pasangan kata yang memiliki jumlah gaps maksimum sebanyak dua pada setiap kata.</p>
</li>
<li>
<p>ROUGE-SU merupakan pengembangan dari </p>
</li>
<li>
<p>ROUGE-S yang memperhatikan unigram.</p>
</li>
<li>
<p>ROUGE-W yang menggunakan LCS namun tidak memberikan preferensi pada kalimat yang emiliki kata-kata yang lebih berurutan.</p>
</li>
</ul>
<p>Untuk mengukur keakuratan ringkasan harus menghitung Precision, Recall, dan F-Measure.</p>
<ul>
<li>
<p>Rumus menghitung recall adalah banyaknya kata yang overlap dibagi dengan banyaknya kata pada ringkasan rujukan.</p>
</li>
<li>
<p>Rumus menghitung Precision adalah banyaknya kata yang overlap dibagi dengan banyaknya kata pada ringkasan mesin</p>
</li>
</ul>
<p>F-Measure merupakan salah satu perhitungan evalusasi dalam informasi temu kembali yang mengkombinasikan recall dan precission. Nilai recall  dan Precission pada suatu keadaan dapat memiliki bobot yang berbeda. Ukuran yang menampilkan timbal balik antara Recall dan Precission adalah F-Measure yang merupakan bobot harmonic mean dan reall dan precission.</p>
<p><img alt="rumusfmeasure" src="f-measure.jpg" /></p>
<p>Implementasi program:</p>
<pre><code class="language-python">from rouge.rouge import rouge_n_sentence_level
summary_sentence = 'Awal terjadinya kesyirikan adalah di zaman Nabi Nuh ‘alaihissalam'.split()
reference_sentence = 'Di zaman Nabi Nuh ‘alaihissalam adalah awal terjadinya kesyirikan'.split()

#Menghitung nilai rouge
recall, precision, rouge = rouge_n_sentence_level(summary_sentence, reference_sentence, 2)
print ('ROUGE-2-R', recall)
print ('ROUGE-2-P', precision)
print ('ROUGE-2-F', rouge)
</code></pre>
<p>Output: </p>
<pre><code class="language-output">ROUGE-2-R 0.5
ROUGE-2-P 0.5
ROUGE-2-F 0.5
</code></pre>
                
              
              
                


              
            </article>
          </div>
        </div>
        
      </main>
      
        
<footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
        
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": ".", "features": [], "translations": {"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing"}, "search": "assets/javascripts/workers/search.d351de03.min.js", "version": null}</script>
    
    
      <script src="assets/javascripts/bundle.a1609d9a.min.js"></script>
      
    
  </body>
</html>